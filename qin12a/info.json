{
    "abstract": "We consider a class of sparse learning problems in high dimensional feature space regularized by a structured sparsity-inducing norm that incorporates prior knowledge of the group structure of the features.  Such problems often pose a considerable challenge to optimization algorithms due to the non-smoothness and non-separability of the regularization term.  In this paper, we focus on two commonly adopted sparsity-inducing regularization terms, the overlapping Group Lasso penalty <i>l<sub>1</sub>/l<sub>2</sub></i>-norm and the <i>l<sub>1</sub>/l<sub>&#8734;</sub></i>-norm.  We propose a unified framework based on the augmented Lagrangian method, under which problems with both types of regularization and their variants can be efficiently solved.  As one of the core building-blocks of this framework, we develop new algorithms using a partial-linearization/splitting technique and prove that the accelerated versions of these algorithms require <i>O(1/&#8730;&#949;)</i> iterations to obtain an <i>&#949;</i>-optimal solution.  We compare the performance of these algorithms against that of the alternating direction augmented Lagrangian and FISTA methods on a collection of data sets and apply them to two real-world problems to compare the relative merits of the two norms.",
    "authors": [
        "Zhiwei Qin",
        "Donald Goldfarb"
    ],
    "id": "qin12a",
    "issue": 47,
    "pages": [
        1435,
        1468
    ],
    "title": "Structured Sparsity via Alternating Direction Methods",
    "volume": "13",
    "year": "2012"
}