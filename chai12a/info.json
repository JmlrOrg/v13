{
    "abstract": "Gaussian process prior with an appropriate likelihood function is a flexible non-parametric model for a variety of learning tasks.  One important and standard task is multi-class classification, which is the categorization of an item into one of several fixed classes.  A usual likelihood function for this is the multinomial logistic likelihood function.  However, exact inference with this model has proved to be difficult because high-dimensional integrations are required.  In this paper, we propose a variational approximation to this model, and we describe the optimization of the variational parameters.  Experiments have shown our approximation to be tight.  In addition, we provide data-independent bounds on the marginal likelihood of the model, one of which is shown to be much tighter than the existing variational mean-field bound in the experiments.  We also derive a proper lower bound on the predictive likelihood that involves the Kullback-Leibler divergence between the approximating and the true posterior.  We combine our approach with a recently proposed sparse approximation to give a variational sparse approximation to the Gaussian process multi-class  model.  We also derive criteria which can be used to select the inducing set, and we show the effectiveness of these criteria over random selection in an experiment.",
    "authors": [
        "Kian Ming A. Chai"
    ],
    "id": "chai12a",
    "issue": 55,
    "pages": [
        1745,
        1808
    ],
    "title": "Variational Multinomial Logit Gaussian Process",
    "volume": "13",
    "year": "2012"
}